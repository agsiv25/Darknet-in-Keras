{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters here \n",
    "INPUT_SIZE = 256\n",
    "mapping = {0:'normal', 1:'other'}\n",
    "NUMCLASSES = len(mapping)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "folder = r'C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest Xray\\nih'\n",
    "SEED = 12345\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "def preprocess(img):\n",
    "    # Contrast stretching\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    \n",
    "    # Histogram Equalization\n",
    "    #img_eq = exposure.equalize_hist(img)\n",
    "\n",
    "    # Adaptive Equalization\n",
    "    #img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    \n",
    "    return img_rescale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                                featurewise_center=False,\n",
    "                                samplewise_center=False,\n",
    "                                featurewise_std_normalization=False,\n",
    "                                samplewise_std_normalization=False,\n",
    "                                zca_whitening=False,\n",
    "                                zca_epsilon=1e-06,\n",
    "                                rotation_range=0,\n",
    "                                width_shift_range=0.0,\n",
    "                                height_shift_range=0.0,\n",
    "                                brightness_range=None,\n",
    "                                shear_range=0.0,\n",
    "                                zoom_range=0.0,\n",
    "                                channel_shift_range=0.0,\n",
    "                                fill_mode=\"nearest\",\n",
    "                                cval=0.0,\n",
    "                                horizontal_flip=False,\n",
    "                                vertical_flip=False,\n",
    "                                rescale=1./255,\n",
    "                                preprocessing_function=preprocess,\n",
    "                                data_format=None,\n",
    "                                validation_split=0.2,\n",
    "                                dtype=None,\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal    50500\n",
      "other     35790\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(folder + r'\\allfiles.csv')\n",
    "df = df[df.label!='pneumonia']\n",
    "# This next line is to use only some x% of the data\n",
    "df = df.sample(frac=1)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30795</th>\n",
       "      <td>C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46509</th>\n",
       "      <td>C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27011</th>\n",
       "      <td>C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30480</th>\n",
       "      <td>C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename   label\n",
       "30795  C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...  normal\n",
       "10022  C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...  normal\n",
       "46509  C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...  normal\n",
       "27011  C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...  normal\n",
       "30480  C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest...  normal"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 10116 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60940 validated image filenames belonging to 2 classes.\n",
      "Found 15234 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_dataframe(\n",
    "                                            dataframe=df,\n",
    "                                            directory='',\n",
    "                                            x_col=\"filename\",\n",
    "                                            y_col=\"label\",\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            classes=None,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True,\n",
    "                                            seed=None,\n",
    "                                            save_to_dir=None,\n",
    "                                            save_prefix=\"\",\n",
    "                                            save_format=\"png\",\n",
    "                                            subset='training',\n",
    "                                            interpolation=\"nearest\",\n",
    "                                            validate_filenames=True\n",
    "                                        )\n",
    "\n",
    "validation_set = train_datagen.flow_from_dataframe( dataframe=df,\n",
    "                                            directory='',\n",
    "                                            x_col=\"filename\",\n",
    "                                            y_col=\"label\",\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            classes=None,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True,\n",
    "                                            seed=None,\n",
    "                                            save_to_dir=None,\n",
    "                                            save_prefix=\"\",\n",
    "                                            save_format=\"png\",\n",
    "                                            subset='validation',\n",
    "                                            interpolation=\"nearest\",\n",
    "                                            validate_filenames=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60944\n"
     ]
    }
   ],
   "source": [
    "print(len(training_set)*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(ni, nf, size=3, stride=1):\n",
    "    ni = 'ignored'\n",
    "    return Sequential([\n",
    "        Conv2D(nf, kernel_size=size, strides=stride, padding='same', bias=False), \n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1)  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_conv(ni, nf):\n",
    "    return Sequential([\n",
    "        conv_block(ni, nf),\n",
    "        conv_block(nf, ni, size=1),  \n",
    "        conv_block(ni, nf)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpooling():\n",
    "    return MaxPool2D(2, strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, kernel_size=3, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arung\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, kernel_size=3, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, kernel_size=3, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, kernel_size=1, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=3, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, kernel_size=1, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, kernel_size=3, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=1, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, kernel_size=3, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, kernel_size=1, strides=1, padding=\"same\", use_bias=False)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 256, 256, 8)       248       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 128, 128, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 64, 64, 32)        10048     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   (None, 32, 32, 64)        39552     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "sequential_15 (Sequential)   (None, 16, 16, 128)       156928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "sequential_19 (Sequential)   (None, 8, 8, 256)         625152    \n",
      "_________________________________________________________________\n",
      "sequential_20 (Sequential)   (None, 8, 8, 128)         33280     \n",
      "_________________________________________________________________\n",
      "sequential_21 (Sequential)   (None, 8, 8, 256)         295936    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 25090     \n",
      "=================================================================\n",
      "Total params: 1,450,874\n",
      "Trainable params: 1,447,146\n",
      "Non-trainable params: 3,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=[INPUT_SIZE,INPUT_SIZE,3])) #keras will internally add batch dimension\n",
    "model.add(conv_block(3, 8))\n",
    "model.add(maxpooling())\n",
    "model.add(conv_block(8, 16))\n",
    "model.add(maxpooling())\n",
    "model.add(triple_conv(16, 32))\n",
    "model.add(maxpooling())\n",
    "model.add(triple_conv(32, 64))\n",
    "model.add(maxpooling())\n",
    "model.add(triple_conv(64, 128))\n",
    "model.add(maxpooling())\n",
    "model.add(triple_conv(128, 256))\n",
    "model.add(conv_block(256, 128, size=1))\n",
    "model.add(conv_block(128, 256))\n",
    "model.add(Conv2D(256, 2))\n",
    "model.add(BatchNormalization()),\n",
    "model.add(ReLU())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.003), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "WARNING:tensorflow:From C:\\Users\\arung\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node sequential_2/conv2d_1_1/convolution}}]]\n\t [[metrics/accuracy/Identity/_579]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node sequential_2/conv2d_1_1/convolution}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-34ee42437861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                    validation_steps = len(validation_set))\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model-normalized-fresh.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node sequential_2/conv2d_1_1/convolution}}]]\n\t [[metrics/accuracy/Identity/_579]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node sequential_2/conv2d_1_1/convolution}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "#Training\n",
    "#c_weights = {0: 0.4, 1: 0.6}\n",
    "\n",
    "for epoch in range(0,50):\n",
    "    print(\"Epoch\",epoch)\n",
    "    if epoch != 0:\n",
    "        # Load Model Weights\n",
    "        model.load_weights('model-normalized-fresh.h5')    \n",
    "    history = model.fit_generator(training_set,\n",
    "    steps_per_epoch=len(training_set),\n",
    "                   epochs=1,\n",
    "                   validation_data=validation_set,\n",
    "                   validation_steps = len(validation_set))\n",
    "\n",
    "    model.save_weights(\"model-normalized-fresh.h5\")\n",
    "    print(\"Saved model to disk after\",epoch+1,\"epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'],color='red')\n",
    "plt.plot(history.history['acc'],color='green')\n",
    "plt.plot(history.history['val_loss'],color='magenta')\n",
    "plt.plot(history.history['val_acc'],color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(folder + r'\\alltestfiles.csv')\n",
    "df_test = df_test[df_test.label!='pneumonia']\n",
    "# This next line is to use only x% of the data\n",
    "df_test = df_test.sample(n = df_test.shape[0]//20)\n",
    "print(df_test['label'].value_counts())\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                featurewise_center=False,\n",
    "                                samplewise_center=False,\n",
    "                                featurewise_std_normalization=False,\n",
    "                                samplewise_std_normalization=False,\n",
    "                                zca_whitening=False,\n",
    "                                zca_epsilon=1e-06,\n",
    "                                rotation_range=0,\n",
    "                                width_shift_range=0.0,\n",
    "                                height_shift_range=0.0,\n",
    "                                brightness_range=None,\n",
    "                                shear_range=0.0,\n",
    "                                zoom_range=0.0,\n",
    "                                channel_shift_range=0.0,\n",
    "                                fill_mode=\"nearest\",\n",
    "                                cval=0.0,\n",
    "                                horizontal_flip=False,\n",
    "                                vertical_flip=False,\n",
    "                                rescale=None,\n",
    "                                preprocessing_function=preprocess,\n",
    "                                data_format=None,\n",
    "                                validation_split=0.0,\n",
    "                                dtype=None,\n",
    "                            )\n",
    "\n",
    "test_set = test_datagen.flow_from_dataframe(\n",
    "                                            dataframe=df_test,\n",
    "                                            directory='',\n",
    "                                            x_col=\"filename\",\n",
    "                                            y_col=\"label\",\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            classes=None,\n",
    "                                            class_mode=None,\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False,\n",
    "                                            seed=None,\n",
    "                                            save_to_dir=folder + '\\\\test',\n",
    "                                            save_prefix=\"\",\n",
    "                                            save_format=\"png\",\n",
    "                                            subset='training',\n",
    "                                            interpolation=\"nearest\",\n",
    "                                            validate_filenames=True\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict_generator(test_set,verbose=1,steps=len(test_set)/1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "predicted_class_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = np.zeros([NUMCLASSES,NUMCLASSES],'float32')\n",
    "count = 0\n",
    "for row in df_test['label']:\n",
    "    if row=='normal':\n",
    "        realclass = 0\n",
    "    else:\n",
    "        realclass = 1\n",
    "    try:\n",
    "        conf[realclass,predicted_class_indices[count]] += 1\n",
    "    except:\n",
    "        break\n",
    "    count += 1\n",
    "    \n",
    "conf[0,:] /= 496\n",
    "conf[1,:] /= 779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
